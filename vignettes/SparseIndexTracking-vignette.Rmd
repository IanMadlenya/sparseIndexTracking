---
title: "Design of Portfolio of Stocks to Track an Index"
author: "Konstantinos Benidis and Daniel P. Palomar"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:  
    base_format: prettydoc::html_pretty
    theme: tactile
    highlight: vignette
    fig_caption: yes
    number_sections: no
    toc: yes
    toc_depth: 2
  bookdown::pdf_document2:
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
indent: yes
csl: ieee.csl
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{Design of portfolio of stocks to track an index}
  %\VignetteKeyword{sparse, portfolio, financial index, tracking}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, echo = FALSE}
library(knitr)
opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.retina = 2,
  out.width = "75%",
  dpi = 96
)
knit_hooks$set(pngquant = hook_pngquant)
#Help on bookdown: https://bookdown.org/yihui/bookdown/
#rmarkdown::render("vignettes/SparseIndexTracking-vignette.Rmd", "all")
#rmarkdown::render("vignettes/SparseIndexTracking-vignette.Rmd", "bookdown::pdf_document2")
#rmarkdown::render("vignettes/SparseIndexTracking-vignette.Rmd", "bookdown::html_document2")
#tools::compactPDF("vignettes/SparseIndexTracking-vignette.pdf", gs_quality = "ebook")
```

-----------
> This vignette illustrates the design of sparse portfolios that aim to track a financila index with the package `sparseIndexTracking` (with a comparison with other packages) and gives a description of the algorithms used.


# Comparison with other packages


# Usage of the package
We start by loading the package and real data of the index S&P 500 and its underlying assets. 
```{r}
library(sparseIndexTracking)
# load('data/data_2010_2015.RData')
```
The file `data_2010_2015.RData` contains three quantities:
[Benidis: this is totally wrong. They are xts, you don't need the field dates. And read my email about the file having only one object (a list) with two elements: X and SP500. BTW, I wouldn't call X lin_returns because SP500 is also lin_returns, so just use X and SP500.]

> 1. `lin_returns`: A $T\times N$ array with the daily linear returns of the $N$ assets that were in the index during the period 2010-2015 (total $T$ trading days)
2. `SP500`: A $T\times 1$ array with the daily linear returns of the index S\&P 500 during the period 2010-2015
3. `dates`: A $T\times 1$ array with the actual dates of the trading days of the period 2010-2015 

Based on the above quantities we create a training window, which we will use to create our portfolios, and a testing window, which will be used to assess the performance of the designed portfolios. For simplicity, here we consider the first six (trading) months of the dataset (around 126 days) as the training window, and the subsequent six months as the testing window.
```{r}
X_train <- lin_returns[1:126,]
X_test <- lin_returns[127:252,]
r_train <- SP500[1:126]
r_test <- SP500[127:252]
dates_test <- dates[127:252]
```

Now, we use the four modes of the `spIndexTracking()` algorithm to design our portfolios.
```{r}
# ETE
lambda <- 1e-7
w_ete <- spIndexTrack(X_train, r_train, lambda, u=0.5, measure='ete')
cat('Number of assets used:', sum(w_ete > 1e-6))

# DR
lambda <- 2e-8
w_dr <- spIndexTrack(X_train, r_train, lambda, u=0.5, measure='dr')
cat('Number of assets used:', sum(w_dr > 1e-6))

# HETE
lambda <- 8e-8
w_hete <- spIndexTrack(X_train, r_train, lambda, u=0.5, measure='hete', hub=0.05)
cat('Number of assets used:', sum(w_hete > 1e-6))

# HDR
lambda <- 2e-8
w_hdr <- spIndexTrack(X_train, r_train, lambda, u=0.5, measure='hdr', hub=0.05)
cat('Number of assets used:', sum(w_hdr > 1e-6))
```

Finally, we plot the actual value of the index in the testing window in comparison with the values of the designed portfolios.
```{r, fig.height = 7, fig.width = 7}
par(mfcol = c(4, 1))
matplot(dates_test, cbind(cumprod(1 + X_test %*% w_ete$w), cumprod(1 + r_test)),
        type = 'l', xlab = 'Days', ylab = 'Wealth', xaxt='n')
axis.Date(1, at=dates_test, format='%b %y', cex.axis = .7)
legend("topleft", c('Portfolio (ETE)', 'S&P 500'), col = seq_len(2), fill=seq_len(2), cex=0.8, bty='n')
grid()

matplot(dates_test, cbind(cumprod(1 + X_test %*% w_dr$w), cumprod(1 + r_test)),
        type = 'l', xlab = 'Days', ylab = 'Wealth', xaxt='n')
axis.Date(1, at=dates_test, format='%b %y', cex.axis = .7)
legend("topleft", c('Portfolio (DR)', 'S&P 500'), col = seq_len(2), fill=seq_len(2), cex=0.8, bty='n')
grid()

matplot(dates_test, cbind(cumprod(1 + X_test %*% w_hete$w), cumprod(1 + r_test)),
        type = 'l', xlab = 'Days', ylab = 'Wealth', xaxt='n')
axis.Date(1, at=dates_test, format='%b %y', cex.axis = .7)
legend("topleft", c('Portfolio (HETE)', 'S&P 500'), col = seq_len(2), fill=seq_len(2), cex=0.8, bty='n')
grid()

matplot(dates_test, cbind(cumprod(1 + X_test %*% w_hdr$w), cumprod(1 + r_test)),
        type = 'l', xlab = 'Days', ylab = 'Wealth', xaxt='n')
axis.Date(1, at=dates_test, format='%b %y', cex.axis = .7)
legend("topleft", c('Portfolio (HDR)', 'S&P 500'), col = seq_len(2), fill=seq_len(2), cex=0.8, bty='n')
grid()
```
In the above examples we used a single training and testing window. In practice, we need to perform this task sequentially for many windows in order to assess an algorithm or to distinguish the differences between the various tracking errors. In the following figures, we have applied the four modes of the algorithm in the index S&P 500 considering different periods and different training and testing window lengths.  

TO ADD PLOTS - HOW MANY?

# Explanation of the algorithms

## `spIndexTrack()`: Sparse portfolio construction

Assume that an index is composed of $N$ assets. We denote by $\mathbf{r}^b=[r_1^b,\dots,r_T^b]^\top\in\mathbb{R}^T$ and $\mathbf{X}=[\mathbf{r}_1,\dots,\mathbf{r}_T]^\top\in\mathbb{R}^{T\times N}$ the (arithmetic) net returns of the index and the $N$ assets in the past $T$ days, respectively, with $\mathbf{r}_t\in\mathbb{R}^N$ denoting the net returns of the $N$ assets at the $t$-th day.

The goal of `spIndexTrack()` is the design of a (sparse) portfolio $\mathbf{w}\in\mathbb{R}_+^N$, with $\mathbf{w}^\top\mathbf{1} = 1$, that tracks closely the index, i.e., $\mathbf{X}\mathbf{w} \approx \mathbf{r}^b$, based on [@BenFengPal2018]. The underlying optimization problem that is solved is

\begin{equation}
\begin{array}{ll}
\underset{\mathbf{w}}{\text{minimize}} & \text{TE}(\mathbf{w}) + \lambda\|\mathbf{w}\|_0\\
\textsf{subject to}
 & \mathbf{w}^\top\mathbf{1}=1\\
 & \mathbf{0}\leq\mathbf{w}\leq u\mathbf{1},
\end{array} 
(\#eq:general-form)
\end{equation}
\noindent where $\text{TE}(\mathbf{w})$ is a general tracking error (we will see specific tracking errors shortly), $\lambda$ is a regularization parameter that controls the sparsity of the portfolio, and $u$ is an upper bound on the weights of the portfolio.

The $\ell_0$-"norm" is approximated by the continuous and differentiable (for $w \geq 0$) function

\begin{equation}
\rho_{p,u}(w) = \frac{\log(1 + w/p)}{\log(1 + u/p)},
\end{equation}
\noindent where $p>0$ is a parameter that controls the approximation. This leads to the following approximate problem:

\begin{equation}
\begin{array}{ll}
\underset{\mathbf{w}}{\text{minimize}} & \text{TE}(\mathbf{w}) + \lambda\mathbf{1}^\top\boldsymbol{\rho}_{p,u}(\mathbf{w})\\
\textsf{subject to}
 & \mathbf{w}^\top\mathbf{1}=1\\
 & \mathbf{0}\leq\mathbf{w}\leq u\mathbf{1},
\end{array}
(\#eq:approx-form)
\end{equation}
\noindent where $\boldsymbol{\rho}_{p,u}(\mathbf{w})=[\mathbf{\rho}_{p,u}(w_1),\dots,\rho_{p,u}(w_N)]^\top$.

There are four available tracking errors $\text{TE}(\mathbf{w}$) in `spIndexTrack()`:

* Empirical tracking error (ETE):

$$
\text{ETE}(\mathbf{w}) = \frac{1}{T}\big\|\mathbf{r}^b - \mathbf{X}\mathbf{w}\big\|_2^2
$$

* Downside risk (DR):

$$
\text{DR}(\mathbf{w}) = \frac{1}{T}\big\|(\mathbf{r}^b-\mathbf{X}\mathbf{w})^+\big\|_2^2
$$     

* Huber empirical tracking error (HETE):

$$
\text{HETE}(\mathbf{w}) = \frac{1}{T}\mathbf{1}^\top\boldsymbol{\phi}\left(\mathbf{r}^b - \mathbf{X}\mathbf{w}\right)
$$ 

* Huber downside risk (HDR):

$$
\text{HDR}(\mathbf{w}) = \frac{1}{T}\mathbf{1}^\top\boldsymbol{\phi}\left((\mathbf{r}^b-\mathbf{X}\mathbf{w})^+\right)
$$ 
where $\boldsymbol{\phi}(\mathbf{x}) = [\phi(x_1), \dots, \phi(x_T)]^\top$ and 
$$
\phi(x) = \begin{cases}
x^2 &\quad |x| \leq M\\
M(2|x| - M) &\quad |x| > M,
\end{cases}
$$
with $M>0$ being the Huber parameter.


Regardless of the selected tracking error measure, problem \@ref(eq:approx-form) can be solved via Majorization-Minimization (MM) [@SunBabPal2018] with an iterative closed-form update algorithm (with iterations denoted by $k$). It can be shown that all of the above variations boil down to the iterative optimization of the following convex problem:

\begin{equation}
\begin{array}{ll}
\underset{\mathbf{w}}{\text{minimize}} & \mathbf{w}^\top\mathbf{w} + {\mathbf{q}^{(k)}}^\top\mathbf{w}\\
\textsf{subject to} & \mathbf{w}\in\mathcal{W}_{u},
\end{array} 
(\#eq:MM-iterative-form)
\end{equation}
\noindent where 
$$
\mathcal{W}_{u} = \big\{\mathbf{w} \big| \mathbf{w}^\top\mathbf{1} = 1, \mathbf{0}\leq\mathbf{w}\leq u\mathbf{1}\big\},
$$
and $\mathbf{q}^{(k)}\in\mathbb{R}^N$. 

What differentiates the various tracking errors is the exact form of $\mathbf{q}^{(k)}$ that we need to compute at each iteration $k$ of the algorithm:
$$
\begin{aligned}
  \mathbf{q}_{\text{ETE}}^{(k)} & = \frac{1}{\lambda_{\text{max}}^{(\mathbf{L}_1)}}(2(\mathbf{L}_1 - \lambda_{\text{max}}^{(\mathbf{L}_1)}\mathbf{I})\mathbf{w}^{(k)} + \lambda{\mathbf{d}_{p,u}^{(k)}} -\frac{2}{T}\mathbf{X}^\top\mathbf{r}^b),\\
  \mathbf{q}_{\text{DR}}^{(k)} & = \frac{1}{\lambda_{\text{max}}^{(\mathbf{L}_1)}} (\frac{2}{T} 2(\mathbf{L}_1 - \lambda_{\text{max}}^{(\mathbf{L}_1)}\mathbf{I})\mathbf{w}^{(k)} + \lambda\mathbf{d}_{p,u}^{(k)} + \frac{2}{T}\mathbf{X}^\top(\mathbf{y}^{(k)} - \mathbf{r}^b)),\\
  \mathbf{q}_{\text{HETE}}^{(k)} & = \frac{1}{\lambda_{\text{max}}^{(\mathbf{L}_2)}}(2(\mathbf{L}_2 - \lambda_{\text{max}}^{(\mathbf{L}_2)}\mathbf{I})\mathbf{w}^{(k)} + \lambda{\mathbf{d}_{p,u}^{(k)}} -\frac{2}{T}\mathbf{X}^\top\text{Diag}(\mathbf{a}^{(k)})\mathbf{r}^b),\\ 
  \mathbf{q}_{\text{HDR}}^{(k)} & = \frac{1}{\lambda_{\text{max}}^{(\mathbf{L}_3)}}(2(\mathbf{L}_3 - \lambda_{\text{max}}^{(\mathbf{L}_3)}\mathbf{I})\mathbf{w}^{(k)} + \lambda{\mathbf{d}_{p,u}^{(k)}} +\frac{2}{T}\mathbf{X}^\top\text{Diag}(\mathbf{b}^{(k)})(\mathbf{c}^{(k)} - \mathbf{r}^b)),
\end{aligned}
$$
where $\lambda_{\text{max}}^{(\mathbf{A})}$ denotes the maximum eigenvalue of a matrix $\mathbf{A}$, $\mathbf{I}$ denotes the identity matrix, $\text{Diag}(\mathbf{x})$ is a diagonal matrix with the vector $\mathbf{x}$ at its principal diagonal, and  
$$
\begin{aligned}
  \mathbf{d}_{p,u}^{(k)} & = \left[d_{p,u}(w_1^{(k)}),\dots,d_{p,u}(w_N^{(k)})\right]^\top,\\
	d_{p,u}(w^{(k)}) & = \frac{1}{\log(1 + u/p)(p+w^{(k)})},\\
	\mathbf{y}^{(k)} & = -(\mathbf{X}\mathbf{w}^{(k)} - \mathbf{r}^b)^+,\\
	\mathbf{a}^{(k)} & = [a([\mathbf{r}^b - \mathbf{X}\mathbf{w}^{(k)}]_1),\dots,a([\mathbf{r}^b - \mathbf{X}\mathbf{w}^{(k)}]_T)]^\top,\\
	a(x) & = \begin{cases} 1 &\quad |x|\leq M\\
	\frac{M}{|x|} &\quad |x| > M,\end{cases}\\
	\mathbf{b}^{(k)} & = [b([\mathbf{r}^b - \mathbf{X}\mathbf{w}^{(k)}]_1),\dots,b([\mathbf{r}^b - \mathbf{X}\mathbf{w}^{(k)}]_T)]^\top,\\
	b(x) & = \begin{cases} \frac{M}{M - 2x} &\quad x < 0\\
	1 &\quad0\leq x\leq M\\
	\frac{M}{x} &\quad x > M,\end{cases}\\
	\mathbf{c}^{(k)} & = [c([\mathbf{r}^b - \mathbf{X}\mathbf{w}^{(k)}]_1),\dots,c([\mathbf{r}^b - \mathbf{X}\mathbf{w}^{(k)}]_T)]^\top,\\
	c(x) & = \begin{cases} x &\quad x < 0\\
	0 &\quad x \geq 0,\end{cases}\\
	\mathbf{L}_1 & = \frac{1}{T}\mathbf{X}^\top\mathbf{X},\\
	\mathbf{L}_2 & = \frac{1}{T}\mathbf{X}^\top\text{Diag}(\mathbf{a}^{(k)})\mathbf{X},\\
	\mathbf{L}_3 & = \frac{1}{T}\mathbf{X}^\top\text{Diag}(\mathbf{b}^{(k)})\mathbf{X}.
\end{aligned}
$$

The following propositions provide a waterfilling structured solution of problem \@ref(eq:MM-iterative-form), considering two special cases, namely, $u=1$ and $u<1$.

```{proposition, name = "AS$_1$", label = "AS1"}
The optimal solution of the optimization problem \@ref(eq:MM-iterative-form) with $u=1$ is
  $$\mathbf{w}^\star = \left(-\frac{1}{2}(\mu\mathbf{1} + \mathbf{q})\right)^+,$$	
  with $$\mu = -\frac{\sum_{i\in\mathcal{A}}q_i + 2}{\text{card}(\mathcal{A})},$$	
  and $$\mathcal{A} = \big\{j \big| \mu + q_j < 0\big\},$$	
  where $\mathcal{A}$ can be determined in $O(\log(N))$ steps. 

```{proposition, name = "AS$_u$", label = "ASu"}
The optimal solution of the optimization problem \@ref(eq:MM-iterative-form) with $u<1$ is
  $$\mathbf{w}^\star = \left(\min\left(-\frac{1}{2}(\mu\mathbf{1} + \mathbf{q}),u\mathbf{1}\right)\right)^+,$$	
  with $$\mu = -\frac{\sum_{j\in\mathcal{B}_2}q_j + 2 - \text{card}(\mathcal{B}_1)2u}{\text{card}(\mathcal{B}_2)},$$	
  and $$\begin{aligned}
	\mathcal{B}_1 &= \big\{j \big| \mu + q_j \leq -2u\big\},\\
	\mathcal{B}_2 &= \big\{j \big| -2u < \mu + q_j < 0\big\},
	\end{aligned}$$	
  where $\mathcal{B}_1$ and $\mathcal{B}_2$ can be determined in $O(N\log(N))$ steps. 
```  
We refer to the iterative procedure of Proposition \@ref(prp:AS1) as AS$_{1}(\mathbf{q})$ (Active-Set for $u=1$) and of Proposition \@ref(prp:ASu) as AS$_u(\mathbf{q})$ (Active-Set for general $u<1$). The iterative closed-form update algorithm is given in Algorithm 1 (where AS$_{1|u}(\mathbf{q})$ means AS$_1(\mathbf{q})$ or AS$_u(\mathbf{q})$).

> **Algorithm 1**  
  1. Set $k=0$ and choose an initial point $\mathbf{w}^{(0)}$ (by default set to $\mathbf{w}^{(0)} = \frac{1}{N}\mathbf{1}$)  
  2. Compute $\mathbf{q}$ according to the selected tracking error  
  3. Find the optimal solution $\mathbf{w}^\star$ with AS$_{1|u}(\mathbf{q})$ and set it equal to $\mathbf{w}^{(k+1)}$  
  4. $k \gets k+1$  
  5. Repeat steps 2-4 until convergence  
  6. Return $\mathbf{w}^{(k)}$  

Finally, note that the approximate problem is controlled by the parameter $p$, and in particular, as $p\rightarrow0$ we get  $\rho_{p,u}\rightarrow\ell_0$. However, by setting small values to $p$, it is likely that the algorithm will get stuck to a local minimum. To solve this issue we start with large values for $p$, i.e., a "loose" approximation, and solve the corresponding optimization problem. Then, we sequentially decrease $p$, i.e., we "tighten" the approximation, and solve the problem again using the previous solution as an initial point. In practice we are interested only in the last, "tightest" problem. For each problem that is solved (i.e., for fixed $p$) we utilize an acceleration scheme that increases the convergence speed of the MM algorithm. For details, please refer to [@Varadhan2008].   



# References {-}
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent
